{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Runs my implementation of Word2Vec\n",
    "## The input is a text file plus some parameters \n",
    "## The pre-processing is performed by functions in TexttoDict\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from TexttoDict import *\n",
    "\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N is the size of hidden layer\n",
    "# inarr, outarr are the output of run_container\n",
    "# inarr is the average of the bag of words\n",
    "# out arr is the middle word in the bag\n",
    "\n",
    "def W2Vtrain(inarr, outarr, hiddensize):\n",
    "# V is the length of cutoff dictionary\n",
    "    V=len(inarr[0])\n",
    "    \n",
    "    \n",
    "# (x,y) are shared variables for (input, output)\n",
    "    x = T.dvector(\"x\") # a vector\n",
    "    y = T.dvector(\"y\") # a vector\n",
    "\n",
    "\n",
    "# (W1,W2) are the weight matrices for input-hidden and hidden-output\n",
    "    W1 = theano.shared(rng.randn(V,hiddensize), name=\"W1\")   # a V x N matrix\n",
    "    W2 = theano.shared(rng.randn(hiddensize,V), name=\"W2\")   # a N x V matrix\n",
    "\n",
    "# This evaluates the hidden and output layers\n",
    "# This is a linear operation, no logistic function unlike neural nets\n",
    "    vhidden = T.dot(x, W1)   \n",
    "    vout = T.dot(vhidden,W2)   \n",
    "\n",
    "# Entropy loss function (this is a scalar)\n",
    "# y is the target word. x in the average of the bag\n",
    "    Entropy = T.dot(y,vout) - T.log((T.exp(vout)).sum())\n",
    "\n",
    "# Compute the gradient of the cost \n",
    "# w.r.t weight vector w and bias term b\n",
    "# These will be updated on each training run\n",
    "    gradW1, gradW2 = T.grad(Entropy, [W1, W2])\n",
    "\n",
    "# The train function updates the weights and computes the entropy\n",
    "    train = theano.function(\n",
    "          inputs=[x,y],\n",
    "          outputs=[Entropy],\n",
    "          updates=((W1, W1 - 0.1 * gradW1),(W2, W2 - 0.1 * gradW2)))\n",
    "\n",
    "# After a sufficient number of training runs, the entropy should vanish\n",
    "    for i in range(len(inarr)):\n",
    "        ent=train(inarr[i], outarr[i])\n",
    "    \n",
    "    return [W1.get_value(), ent,jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599988"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linecount(\"delorme.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-15de3c1bf57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW2Vinput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2vdatafromtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delorme.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreqcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Halmagyi/Documents/Programming/Python/Machine Learning/Word2Vec/Word2Vec/TexttoDict.py\u001b[0m in \u001b[0;36mw2vdatafromtext\u001b[0;34m(tfile, contsize, trainlines, freqcutoff)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mtextdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtextfile_worddict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtextdictcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreqcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mw2vdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtextdictcut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtextdictcut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2vdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2vdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Halmagyi/Documents/Programming/Python/Machine Learning/Word2Vec/Word2Vec/TexttoDict.py\u001b[0m in \u001b[0;36mrun_container\u001b[0;34m(tfile, dictcut, contsize, lines)\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;31m# note contsize is odd so contsize/2 is integer and the middle of the container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0moutarr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munit_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontnr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontsize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add target word to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mcontnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontnr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# delete first word in container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutarr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W2Vinput=w2vdatafromtext(\"delorme.txt\",contsize=7,trainlines=1000,freqcutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myW2Vdata=W2Vtrain(W2Vinput[1],W2Vinput[2],hiddensize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myW2Vdata[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(W2Vinput[0])\n",
    "len(W2Vinput[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2vdatafromtext(tfile,contsize,trainlines,freqcutoff):\n",
    "    textdict=textfile_worddict(tfile,lines=trainlines)\n",
    "    textdictcut=dict_cutoff(textdict,freqcutoff)\n",
    "    w2vdata=run_container(\"textfilesmall.txt\",textdictcut,contsize,lines=trainlines)\n",
    "    return [textdictcut,w2vdata[0],w2vdata[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textdict=textfile_worddict(\"delorme.txt\",lines=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textdictcut=dict_cutoff(textdict,1)\n",
    "w2vdata=run_container(\"delorme.txt\",textdictcut,contsize,lines=trainlines)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
