{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Runs my implementation of Word2Vec\n",
    "## The input is a text file plus some parameters \n",
    "## The pre-processing is performed by functions in TexttoDict\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano import shared\n",
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from TexttoDict import *\n",
    "\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------\n",
    "# C is the size of the bag of words\n",
    "# N is the size of hidden layer\n",
    "# V is length of dictcut\n",
    "# eta is the learning rate\n",
    "\n",
    "class NNet(object):\n",
    "    def __init__(self,V,N,eta):\n",
    "\n",
    "        # inititalizing the weight matrices    \n",
    "        self.W1 = theano.shared(rng.randn(V,N), name=\"W1\")   # a V x N matrix\n",
    "        self.W2 = theano.shared(rng.randn(V,N), name=\"W2\")   # a V x N matrix\n",
    "\n",
    "# (x,y) are shared variables for (input, output)\n",
    "# x is the input bag of words\n",
    "# y is the target word, the middle word in the bag\n",
    "# must be integers since they are indices for matrix elements\n",
    "        x = T.ivector(\"x\") # a vector, dtype=int32\n",
    "        y = T.ivector(\"y\") # a vector, dtype=int32\n",
    "\n",
    "# This evaluates the hidden and output layers\n",
    "# This is a linear operation, no logistic function unlike a typical neural net\n",
    "# To be more precise we are evaluating these at the level of the hidden layer\n",
    "        vhidden = self.W1[x] # a C x N matrix\n",
    "        vout = self.W2[y] # a 1 x N matrix\n",
    "\n",
    "        vhiddenvec= T.mean(vhidden,axis=0)  # an N-vector\n",
    "        voutvec=vout.reshape((N,)) # an N-vector\n",
    "    \n",
    "# Entropy loss function (a scalar)\n",
    "        Entropy = -T.dot(vhiddenvec,voutvec) + T.log(T.exp(T.dot(vhidden,self.W2.T)).sum())\n",
    "\n",
    "# Compute the gradient of the cost wrt the weights\n",
    "# This is the computational power of Theano\n",
    "        gradW1, gradW2 = T.grad(Entropy, [self.W1, self.W2])\n",
    "\n",
    "# The train function updates the weights and computes the entropy\n",
    "        train = theano.function(\n",
    "              inputs=[x,y],\n",
    "              outputs=Entropy,\n",
    "              updates=((self.W1, self.W1 - eta * gradW1),(self.W2, self.W2 - eta * gradW2)))\n",
    "    \n",
    "        self.train=train\n",
    "\n",
    "#---------------------------------------\n",
    "    # outarr is a vector of \n",
    "    def NNettrain(self,inarr, outarr):\n",
    "        for i in range(len(inarr)):\n",
    "            ent=self.train(inarr[i], [outarr[i]])\n",
    "    \n",
    "        return ent\n",
    "    \n",
    "    def returnweights(self):\n",
    "        return self.W1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides the bags of words from the textfile\n",
    "using functions from TexttoDict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W2Vdata=w2vdatafromtext(\"delorme.txt\", contsize=7, trainlines=10000,freqcutoff=5)\n",
    "inarr=np.array(W2Vdata[1]).astype(np.int32)\n",
    "outarr=np.array(W2Vdata[2]).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V=len(W2Vdata[0])\n",
    "N=100\n",
    "eta=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W2VNet=NNet(V,N,eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the final error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.55842341489\n"
     ]
    }
   ],
   "source": [
    "error = W2VNet.NNettrain(inarr, outarr)\n",
    "print error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "returns the weights, this contains the vector representation of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = W2VNet.returnweights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print weights.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
