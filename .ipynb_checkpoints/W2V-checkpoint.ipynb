{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Runs my implementation of Word2Vec\n",
    "## The input is a text file plus some parameters \n",
    "## The pre-processing is performed by functions in TexttoDict\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from TexttoDict import *\n",
    "\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N is the size of hidden layer\n",
    "# V is length of dictcut\n",
    "# C is the size of the bag of words\n",
    "\n",
    "def gettrain(V, N):\n",
    "    \n",
    "# (x,y) are shared variables for (input, output)\n",
    "# x is the input bag of words\n",
    "# y is the target word, the middle word in the bag\n",
    "    x = T.ivector(\"x\") # a vector\n",
    "    y = T.ivector(\"y\") # a vector\n",
    "\n",
    "# (W1,W2) are the weight matrices for input-hidden and hidden-output\n",
    "    W1 = theano.shared(rng.randn(V,N), name=\"W1\")   # a V x N matrix\n",
    "    W2 = theano.shared(rng.randn(V,N), name=\"W2\")   # a V x N matrix\n",
    "\n",
    "# This evaluates the hidden and output layers\n",
    "# This is a linear operation, no logistic function unlike neural nets\n",
    "# To be more precise we are evaluating these at the level of the hidden layer\n",
    "    vhidden = W1[x] # a C x N matrix\n",
    "    vout = W2[y] # a 1 x N matrix\n",
    "\n",
    "    vhiddenvec= T.mean(vhidden,axis=0)  # an N-vector\n",
    "    voutvec=vout.reshape((hiddensize,)) # an N-vector\n",
    "    \n",
    "# Entropy loss function (this is a scalar)\n",
    "    Entropy = -T.dot(vhiddenvec,voutvec) + T.log(T.exp(T.dot(vhidden,W2.T)).sum())\n",
    "\n",
    "# Compute the gradient of the cost wrt the weights\n",
    "    gradW1, gradW2 = T.grad(Entropy, [W1, W2])\n",
    "\n",
    "# The train function updates the weights and computes the entropy\n",
    "    train = theano.function(\n",
    "          inputs=[x,y],\n",
    "          outputs=[Entropy],\n",
    "          updates=((W1, W1 - 0.1 * gradW1),(W2, W2 - 0.1 * gradW2)))\n",
    "   \n",
    "    return train\n",
    "\n",
    "#---------------------------------------\n",
    "# After a sufficient number of training runs, the entropy should vanish\n",
    "\n",
    "\n",
    "def W2Vtrain(inarr,outarr,train):\n",
    "    for i in range(len(inarr)):\n",
    "        ent=train(inarr[i], outarr[i])\n",
    "    \n",
    "    return [W1.get_value(), ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V=1000\n",
    "hiddensize=100\n",
    "train=gettrain(V,hiddensize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(3.579441004943355)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(np.array([1,0]).astype(\"int32\"),np.array([1]).astype(\"int32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def myfun():\n",
    "    def func2(x,y):\n",
    "        return x+y\n",
    "    return func2\n",
    "\n",
    "xyz=myfun()\n",
    "\n",
    "xyz(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599988"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linecount(\"delorme.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-15de3c1bf57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW2Vinput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2vdatafromtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delorme.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreqcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Halmagyi/Documents/Programming/Python/Machine Learning/Word2Vec/Word2Vec/TexttoDict.py\u001b[0m in \u001b[0;36mw2vdatafromtext\u001b[0;34m(tfile, contsize, trainlines, freqcutoff)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mtextdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtextfile_worddict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtextdictcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_cutoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreqcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mw2vdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtextdictcut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtextdictcut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2vdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2vdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Halmagyi/Documents/Programming/Python/Machine Learning/Word2Vec/Word2Vec/TexttoDict.py\u001b[0m in \u001b[0;36mrun_container\u001b[0;34m(tfile, dictcut, contsize, lines)\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;31m# note contsize is odd so contsize/2 is integer and the middle of the container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0moutarr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munit_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontnr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontsize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add target word to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mcontnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontnr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# delete first word in container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minarr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutarr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W2Vinput=w2vdatafromtext(\"delorme.txt\",contsize=7,trainlines=1000,freqcutoff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myW2Vdata=W2Vtrain(W2Vinput[1],W2Vinput[2],hiddensize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myW2Vdata[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(W2Vinput[0])\n",
    "len(W2Vinput[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2vdatafromtext(tfile,contsize,trainlines,freqcutoff):\n",
    "    textdict=textfile_worddict(tfile,lines=trainlines)\n",
    "    textdictcut=dict_cutoff(textdict,freqcutoff)\n",
    "    w2vdata=run_container(\"textfilesmall.txt\",textdictcut,contsize,lines=trainlines)\n",
    "    return [textdictcut,w2vdata[0],w2vdata[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textdict=textfile_worddict(\"delorme.txt\",lines=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textdictcut=dict_cutoff(textdict,1)\n",
    "w2vdata=run_container(\"delorme.txt\",textdictcut,contsize,lines=trainlines)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
